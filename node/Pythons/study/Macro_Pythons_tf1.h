
基础路径设置: 
//base
basePath = Save:node\Pythons\
//classify
classifyPath = base:py_test\classify
	


/***********************************************************************/

// 0~7
// 1. 练习
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.01\] Hello, World
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.02\] time-------------时间
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.03\] if .. else ..
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.04\] while, for
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.05\] cmath------------数学
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.06\] / //-------------整数除法
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.07\] lambda-----------匿名函数
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.08\] match, re--------通配符
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.09\] type, isinstance
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.10\] np
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.11\] tensor, array
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.12\] op---------------加法乘法
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.13\] * **-------------乘方
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.14\] randint
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.15\] import list------常用导入
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.16\] import-----------导入上级目录
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.17\] global nonlocal
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.18\] __dict__
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.19\] graph
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.20\] class
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.21\] _,__
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.22\] yield
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.23\] ndim,size,shape
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.24\] in
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.25\] @tf.function
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.26\] 
// 2. fun
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.1\] str, bytes, bytearray
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.2\] list--------------列表
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.3\] tuple-------------元组
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.4\] dict--------------字典
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.5\] seq---------------序列
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.6\] enumerate---------遍历, 相互转换
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.7\] re
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.8\] DType
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.9\] map---------------映射
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.10\] set--------------集合
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.11\] [i for i in x]---列表(/字典/集合)推导式
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.12\] sorted
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.13\] tf.split, tf.slice
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.14\] detect, coding---编码
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.15\] reduce-----------累积
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.16\] filter-----------过滤
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.17\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.18\] 
// 3. file
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.1\] pd.read_csv
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.2\] df.sample 随机选取
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.3\] mkdir
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.4\] pd.concat--------行列连接
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.5\] df_to_array------相互转换
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.6\] pd.get_dummies---独热编码
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.7\] file, path-------
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.8\] file_read_write
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.9\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.10\] 
// 4. lib
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.1\] math
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.2\] copy
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.3\] json
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.4\] six
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.5\] sklearn.LabelEncoder
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.6\] unittest
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.7\] tqdm-------------进度条库
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.8\] Keras, TFLearn, Sonnet
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.9\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.10\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.11\] Jieba-----------分词
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.12\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.13\] 
// 5. tf
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.1\] tf.Variable()
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.2\] tf.train.Saver.save()
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.3\] tf.add()
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.4\] tf.group(mul, add)
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.5\] tf.gradients-------梯度
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.6\] tf.data.Dataset----tf1.0
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.7\] tf.layers
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.8\] tf.nn.softmax------归一化
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.9\] tf.one_hot
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.10\] tf.logging
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.11\] tf.Estimator------评估器
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.12\] tf.Experiment-----实验类
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.13\] tf.Dataset--------数据集
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.14\] layer_norm
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.15\] accuracy----------准确度
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.16\] tf.reshape
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.17\] tf.gather---------索引提取
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.18\] Hook
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.19\] tf.enable_eager_execution()
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.20\] tf.summary
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.21\] tf.map_fn
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.22\] tf.cond
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.23\] tf.while_loop
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.24\] tf.concat---------行列连接
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.25\] tf.expand_dims
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.26\] tf.logical_and
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.27\] tf.equal
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.28\] tf.argmin
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.29\] transpose
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.30\] 
// 6. tf2.0
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.1\] tf.data.Dataset----tf2.0
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.2\] tf2_model----------Masking
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.3\] tf2_K_maximum
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.4\] tf.py_function
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.5\] tf2_loss
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.6\] tf2_keras_clip-----边界值
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.7\] tf.nn.relu---------激活op
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.8\] tf.nn.conv2d-------卷积op
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.9\] tf.nn.avg_pool-----池化op
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.10\] tf.nn.l2_normalize--归一化op
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.11\] tf.nn....----------其他
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.12\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.13\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.14\] tf2_classify_bys---分类器
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.15\] tf2_Dense----------二分类
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.16\] LogisticRegression-逻辑回归
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.17\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.18\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.19\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.20\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.21\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.22\] 
// 7. Kera
Save:node\Pythons\study\Macro_Pythons_tf1.h \[7.1\] variable constant epsilon
Save:node\Pythons\study\Macro_Pythons_tf1.h \[7.2\] shape int_shape reshape
Save:node\Pythons\study\Macro_Pythons_tf1.h \[7.3\] softmax sigmoid
Save:node\Pythons\study\Macro_Pythons_tf1.h \[7.4\] max min sum prod
Save:node\Pythons\study\Macro_Pythons_tf1.h \[7.5\] any all
Save:node\Pythons\study\Macro_Pythons_tf1.h \[7.6\] square round
Save:node\Pythons\study\Macro_Pythons_tf1.h \[7.7\] clip----------------裁剪
Save:node\Pythons\study\Macro_Pythons_tf1.h \[7.8\] repeat
Save:node\Pythons\study\Macro_Pythons_tf1.h \[7.9\] arange
Save:node\Pythons\study\Macro_Pythons_tf1.h \[7.10\] flatten
Save:node\Pythons\study\Macro_Pythons_tf1.h \[7.11\]





[1.01] Hello, World
//	Hello, World:
py_test\test_Hello_World.py
python py_test\test_Hello_World.py



[1.02] time-------------时间
//time 当前时间戳
py_test\test_time.py
python_w py_test\test_time.py


//%%time
py_test\test_time2.py
python_w py_test\test_time2.py


// path + time
py_test\import_test\test_path.py
python_w py_test\import_test\test_path.py



[1.03] if .. else ..
//if else
py_test\test_if.py
python py_test\test_if.py

//if else
next_sentence_label = 1 if instance.is_random_next else 0



[1.04] while, for
//while
py_test\test_while.py
python py_test\test_while.py

//for_else
py_test\test_for_else.py
python_w py_test\test_for_else.py


[1.05] cmath------------数学
// cmath
py_test\test_cmath.py
python py_test\test_cmath.py



[1.06] / //
//" / "就表示 浮点数除法，返回浮点结果;" // "表示整数除法。



[1.07] lambda-----------匿名函数
//lambda
py_test\test_lambda.py
python py_test\test_lambda.py

//lambda多参数


[1.08] match, re--------通配符
//re
py_test\test_re.py
python py_test\test_re.py


//match
py_test\test_re_match.py
python py_test\test_re_match.py



[1.09] type, isinstance
//isinstance()与type()的区别
//	isinstance() 会认为子类是一种父类类型，考虑继承关系。
//	type() 不会认为子类是一种父类类型，不考虑继承关系。

//	class A:
//	pass
//
//	class B(A):
//	pass
//
//	isinstance(A(), A) # returns True
//	type(A()) == A     # returns True
//	isinstance(B(), A) # returns True
//	type(B()) == A     # returns False




[1.10] np
//	ERR：
py_test\test_np.py
python py_test\test_np.py




[1.11] tensor, array
//	tensor转array:
//    tf.convert_to_tensor(b)
py_test\test_shape.py
python_w py_test\test_shape.py


//str_to_tensor
py_test\tf_str_to_tensor.py
python_w py_test\tf_str_to_tensor.py



[1.12] 加法乘法
//one_hot
py_test\math_op.py
python_w py_test\math_op.py

//list, tensor相加
py_test\math_op1.py
python_w py_test\math_op1.py

//* np.multiply
py_test\math_op2.py
python_w py_test\math_op2.py

//tf.concat
py_test\math_op3.py
python_w py_test\math_op3.py

//tf.concat
py_test\math_op4.py
python_w py_test\math_op4.py

//tf 矩阵
tf.multiply()
tf.matmul()

//不同形状的运算
py_test\math_op5.py
python_w py_test\math_op5.py



[1.13] * ** 乘方
//*  代表乘法
//*  表示倍数 ‘aaa’*3
//参数:
def demo(*p):  是用来接受任意多个参数并将其放在一个元组中
def d(a,b,c):  d(*[1,2,3]), 自动进行解包然后传递给多个单变量参数（参数个数要对应相等）

//** 代表乘方
//参数:
def demo(**p):	**parameter用于接收类似于关键参数一样赋值的形式的多个实参放入字典中（即把该函数的参数转换为字典）。


[1.14] randint
//rand
py_test\test_rand.py
python_w py_test\test_rand.py



[1.15] import list

import os
import modeling
import optimization
import tensorflow as tf
import logging  
import logging.handlers
import sys
import time



[1.16] import
// 导入上级目录
py_test\import_test\A\main_model.py
python_w py_test\import_test\A\main_model.py
	


[1.17] global nonlocal
// global:
若想在函数内部对函数外的变量进行操作，就需要在函数内部声明其为global。
// globals():
globals() 函数会以字典类型返回当前位置的全部全局变量。
// nonlocal



[1.18] __dict__
//	class A(object):
//	obj = A()
//
//	print (A.__dict__)
//		{'a': 0, '__module__': '__main__', 'b': 1, , '__dict__':<> , 
//		 '__init__':<> , 'test':<> , '__weakref__': <>, '__doc__': '', 'static_test': <>}
//	print (obj.__dict__)
//		{'a': 2, 'b': 3}




[1.19] graph
//tf.graph
py_test\tf_graph.py
python_w py_test\tf_graph.py



[1.20] class
//class
py_test\base_class.py
python_w py_test\base_class.py




[1.21] _,__
_var: 内部使用, 不自动导入
var_: 解决命名冲突
__var: 重写属性名称，以避免子类中的命名冲突
__var__:特殊用途
_: 临时变量




[1.22] yield
//yield--数组分隔
py_test\base_yield.py
python_w py_test\base_yield.py

//yield+lambda 冲突
py_test\base_yield_lambda.py
python_w py_test\base_yield_lambda.py



[1.23] ndim,size,shape
d=np.array([[1,2,3],[4,5,6],[7,8,9]])
d.ndim = 2
d.shape = (3, 3)
d.size = 9

//shape
py_test\base_shape.py
python_w py_test\base_shape.py
// tf.shape()中a数据类型可以是tensor，list，array。 返回Tensor
// a.get_shape()中a的数据类型只能是tensor，返回元组。


tf.shape
tf.size
tf.rank
tf.reshape
tf.squeeze
tf.expand_dims
//v = a.get_shape()
//loop = v.num_elements()



[1.24] in
py_test\base_in.py
python_w py_test\base_in.py





[1.25] @tf.function
//
print(tf.autograph.to_code(f))



[1.26] 






[2.1] str, bytes, bytearray
//strip
str.strip()  移除字符串头尾指定的字符

str.join()  连接字符串数组。将字符串、元组、列表中的元素以指定的字符(分隔符)连接生成一个新的字符串
//	a=['1','2','3','4','5']
//	print('  '.join(a))
//	1 2 3 4 5

str.split()
str.split(str="", num=string.count(str)).
//str -- 分隔符，默认为所有的空字符，包括空格、换行(\n)、制表符(\t)等。
//num -- 分割次数。默认为 -1, 即分隔所有。

ord(char) chr(48) unichr(48)  ASCII/Unicode码


//str_bytes_bytearray
py_test\fun_str_bytes.py
python_w py_test\fun_str_bytes.py




[2.2] list---列表
range() 函数可创建一个整数列表

//	s1=set([])　＃列表
//	s2=set(())　＃元组
//	s3=set({})　＃字典

//list 函数
py_test\test_list.py
python_w py_test\test_list.py

//list 一级索引
py_test\test_list_simple.py
python_w py_test\test_list_simple.py

//list 二级索引
py_test\test_list_index.py
python_w py_test\test_list_index.py
	
//list 二级索引 更新值
py_test\test_list_set.py
python_w py_test\test_list_set.py


[2.3] tuple--元组
zip()  接受任意多个（包括0个和1个）序列作为参数，返回一个tuple列表
//xyz = zip(x, y, z)
//      zip([1, 4, 7], [2, 5, 8], [3, 6, 9])
//      [(1, 4, 7), (2, 5, 8), (3, 6, 9)]
//u   = zip(*xyz)
//      [(1, 2, 3), (4, 5, 6), (7, 8, 9)]
//r   = zip(* [x] * 3)
//      [(1, 1, 1), (2, 2, 2), (3, 3, 3)]

//	tuple([1,2,3,4])
//		(1, 2, 3, 4)
//	tuple({1:2,3:4})    #针对字典 会返回字典的key组成的tuple
//		(1, 3)
//	tuple((1,2,3,4))    #元组会返回元组自身
//		(1, 2, 3, 4)
	
// 遍历元组
py_test\test_tuple.py
python_w py_test\test_tuple.py

// 元组->list
py_test\test_tuple_to_list.py
python_w py_test\test_tuple_to_list.py

// 元组
py_test\test_tuple_add.py
python_w py_test\test_tuple_add.py


[2.4] dict---字典
dict()  使用zip创建字典
//dict(zip(key, value))
//      {‘a‘: 1, ‘b‘: 2, ‘c‘: 3}
//dict(dict1, **dict2) 连接两个字典

fromkeys()  创建一个新字典，以序列seq中元素做字典的键，value为字典所有键对应的初始值。
//d=dict.fromkeys(seq,100)

//tn = dict.get(tensor_name, 0)

//dict
py_test\test_dict.py
python_w py_test\test_dict.py


[2.5] seq----序列
//	seq={‘name‘,‘age‘,‘score‘}

//	seq = ['one', 'two', 'three']
//	for i, element in enumerate(seq):
//		print i, element
//		0 one
//		1 two
//		2 three


[2.6] enumerate----遍历, 相互转换
enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。

//	rdm = np.random.mtrand.RandomState(SEED)
//	X = rdm.rand(32, 2)
//	Y_ = [[int(x0 + x1 < 1)] for (x0, x1) in X]


//遍历字典dict
//	for i in dict: 
//	    print "dict[%s]=" % i,dict[i] 

//	for (k,v) in  dict.items(): 
//	     print "dict[%s]=" % k,v 

//	for k,v in dict.iteritems(): 
//	     print "dict[%s]=" % k,v 

//	for k,v in zip(dict.iterkeys(),dict.itervalues()): 
//	     print "dict[%s]=" % k,v 


// 相互转换的方法
py_test\test_list_trans.py
python_w py_test\test_list_trans.py




[2.7] re
compile()  返回的是一个匹配对象，它单独使用就没有任何意义，需要和findall(), search(), match()搭配使用。 
//	regex = re.compile('\w*o\w*')
//		x = regex.findall(content)


//fun_re_search
py_test\fun_re_search.py
python_w py_test\fun_re_search.py


escape()  可以对字符串中所有可能被解释为正则运算符的字符进行转义的应用函数
//  re.escape('www.python.org')
'www\\.python\\.org'
//  re.findall(re.escape('w.py'),"jw.pyji w.py.f")
['w.py', 'w.py']


sub()  是substitude的缩写，表示替换
//  re.sub(r'\w+','10',"xy 15 rt 3e,gep",2,flags=re.I )
'10 10 rt 3e,gep'，

//	string = 'apple pear banana meat'
//	re.sub(r'(apple|banana)\s(\w+)\s?', lambda x: func(ret, x.group(1), x.group(2)), string)
{'apple': 'pear', 'banana': 'meat'}


[2.8] DType
//DType 类
//	定义在：tensorflow/python/framework/dtypes.py.
//
//	参见指南：构建图>张量类型
//
//	表示 TensorFlow 张量中元素的类型. 
//	定义了以下 DType 对象:
//
//	tf.float16：16位半精度浮点数.
//	tf.float32：32位单精度浮点数.
//	tf.float64：64位双精度浮点数.
//	tf.bfloat16：16位截断浮点数.
//	tf.complex64：64位单精度复合.
//	tf.complex128：128位双精度复合.
//	tf.int8：8位有符号整数.
//	tf.uint8：8位无符号整数.
//	tf.uint16：16位无符号整数.
//	tf.int16：16位有符号整数.
//	tf.int32：32位有符号整数.
//	tf.int64：64位有符号整数.
//	tf.bool：布尔值.
//	tf.string：字符串.
//	tf.qint8：量化8位有符号整数.
//	tf.quint8：量化的8位无符号整数.
//	tf.qint16：量化16位有符号整数.
//	tf.quint16：量化16位无符号整数.
//	tf.qint32：量化32位有符号整数.
//	tf.resource：处理可变资源.


//fun_type
py_test\fun_type.py
python_w py_test\fun_type.py










[2.9] map 映射
map()  	会根据提供的函数对指定序列做映射。
第一个参数 function 以参数序列中的每一个元素调用 function 函数，返回包含每次 function 函数返回值的新列表。
//  def square(x) : ...		   # 计算平方数
//  map(square, [1,2,3,4,5])   # 计算列表各个元素的平方
[1, 4, 9, 16, 25]
//  map(lambda x: x ** 2, [1, 2, 3, 4, 5])	# 使用 lambda 匿名函数
[1, 4, 9, 16, 25]
//  提供了两个列表，对相同位置的列表数据进行相加
//  map(lambda x, y: x + y, [1, 3, 5, 7, 9], [2, 4, 6, 8, 10])
[3, 7, 11, 15, 19]

//fun_map
py_test\fun_map.py
python_w py_test\fun_map.py

//map多参数
py_test\fun_map2.py
python_w py_test\fun_map2.py


[2.10] set----集合
集合是一个无序不重复元素的集

//	s1=set([])　＃列表
//	s2=set(())　＃元组
//	s3=set({})　＃字典

//	s1=set([1,2,3,4])
//	{1, 2, 3, 4}
//	　　
//	s3=set({'a':2,'b':3,'c':4})
//	{'c', 'a', 'b'}

set1.add('vivi')
set1.update('abc')
set1.pop()
set1.remove('haha')
set1.clear()
del set1


[2.11] [i for i in x]---列表(/字典/集合)推导式
//列表(/字典/集合)推导式
py_test\fun_for_list.py
python_w py_test\fun_for_list.py




[2.12] sorted
sorted(dict.items(),key=lambda item:item[0])

//	列表排序反向顺序?
newsort = sorted(sort,key=operator.itemgetter(1), reverse = True)


[2.13] tf.split, tf.slice
//tf.split
split0, split1, split2 = tf.split(value, [4, 15, 11], 1)

//tf.slice
b = tf.slice(a, [1, 1], [2, 2])


tf.slice
tf.split
tf.pad
tf.concat
tf.transpose


[2.14] detect, coding---编码
//编码
py_test\fun_coding.py
python_w py_test\fun_coding.py


[2.15] reduce-----------累积
//会对参数序列中元素进行累积
reduce(add, [1,2,3,4,5])



[2.16] filter-----------过滤
//过滤序列，过滤掉不符合条件的元素
filter(is_odd, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])



[2.17] 



[2.18] 


[2.19] 



[2.20] 



[3.1] pd.read_csv
//	read_csv
q_table6 = pd.read_csv('dl_data.csv',encoding = "utf-8",header = 0,names = range(0,50))
q_table6 = pandas.read_csv(filepath_or_buffer, sep=', ', delimiter=None, header='infer', names=None, 
			index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, 
			engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, 
			skiprows=None, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, 
			skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, 
			dayfirst=False, iterator=False, chunksize=None, compression='infer', thousands=None, decimal=b'.', 
			lineterminator=None, quotechar='"', quoting=0, escapechar=None, comment=None, encoding=None, 
			dialect=None, tupleize_cols=None, error_bad_lines=True, warn_bad_lines=True, skipfooter=0, 
			doublequote=True, delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None）

//	不想添加新的行索引
//		index_col=0表示以原有数据的第一列(索引为0)当作行索引。
q_table6 = pd.read_csv('dl_data.csv',encoding = "utf-8",index_col=0)

//	sep=','   # 以，为数据分隔符
//	shkiprows= 10   # 跳过前十行
//	nrows = 10   # 只去前10行
//	parse_dates = ['col_name']   # 指定某行读取为日期格式
//	index_col = ['col_1','col_2']   # 读取指定的几列
//	error_bad_lines = False   # 当某行数据有问题时，不报错，直接跳过，处理脏数据时使用
//	na_values = 'NULL'   # 将NULL识别为空值


[3.2] df.sample 随机选取
df = df.sample(frac=1, random_state = 94).reset_index(drop=True)
DataFrame.sample(n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)[source]

//抽取行的比例 frac=0.8
//random_state=None,取得数据不重复


//reset_index
//数据清洗时，会将带空值的行删除，此时DataFrame或Series类型的数据不再是连续的索引，可以使用reset_index()重置索引。
//print(df.reset_index())
//	   index   0   1   2   3
//	0      1   0   1   2   3
//	1      3   4   5   6   7
//	2      4   8   9  10  11
//	3      6  12  13  14  15
//	4      8  16  17  18  19
//
//不想保留原来的index，使用参数 drop=True，默认 False。
df.reset_index(drop=True)
//
result = pd.concat(frames) 
//这句话改成 
result = pd.concat(frames,ignore_index=True)


[3.3] mkdir
	
if not os.path.exists(self.data_dir):
	os.mkdir(self.data_dir)



[3.4] pd.concat
//将数据根据不同的轴作简单的融合 
//	frames = [df1, df2, df3]
//	result = pd.concat(frames)

//要在相接的时候在加上一个层次的key来识别数据源自于哪张表，可以增加key参数
//	result = pd.concat(frames, keys=['x', 'y', 'z'])

//横向表拼接
//	result = pd.concat([df1, df4], axis=1)

//加上join参数的属性，如果为’inner’得到的是两表的交集，如果是outer，得到的是两表的并集。
//	result = pd.concat([df1, df4], axis=1, join='inner')


[3.5] df_to_array
// df_to_array
py_test\df_to_array.py
python_w py_test\df_to_array.py




[3.6] pd.get_dummies---独热编码
//独热编码
//pd.get_dummies

//sklearn
//	enc = preprocessing.OneHotEncoder()
//	enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])	 # fit来学习编码
//	enc.transform([[0, 1, 3]]).toarray()	# 进行编码
//
//输出：	
//      array([[ 1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.]])

//tf.one_hot()
//	abels = tf.constant([0,1,2]) # 输入的元素值最小为0，最大为2
//	output = tf.one_hot(labels,classes)
//输出：	
//      array([[ 1.,  0.,  0.],
//             [ 0.,  1.,  0.],
//             [ 0.,  0.,  1.]], dtype=float32))


[3.7] file, path
// file, path
py_test\test_path.py
python_w py_test\test_path.py

// path
py_test\import_test\test_path.py
python_w py_test\import_test\test_path.py



[3.8] file_read_write
py_test\

//write
py_test\file_write.py
python_w py_test\file_write.py


//write try
py_test\file_write1.py
python_w py_test\file_write1.py


//write with 
py_test\file_write2.py
python_w py_test\file_write2.py


//read
//py_test\file_read1.py
//python_w py_test\file_read1.py


//read jieba
//py_test\file_read.py
//python_w py_test\file_read.py



[3.9] 


[3.10] 




[4.1] math
Softmax 归一化指数函数


//math_soft
py_test\math_sorted.py
python_w py_test\math_sorted.py

//nan to 0:
//  conv 'nan' to '0'
//  tf.is_nan
//  data.fillna()
//  numpy.nan_to_num(x)
//  embedding_mc = tf.clip_by_value(embedding_mc,1e-8,1.0)


[4.2] copy
//复制
list1 = copy.copy(list)
//深复制
list2 = copy.deepcopy(list)




[4.3] json




[4.4] six
six.iteritems(json_object)




[4.5] sklearn.LabelEncoder
// sklearn.LabelEncoder
//   标签-->id
py_test\lib_sk_LabelEncoder.py
python_w py_test\lib_sk_LabelEncoder.py


sklearn.preprocessing.Normalizer
//	normalizer = preprocessing.Normalizer().fit(X)#
//	normalizer.transform(X)
//	preprocessing.normalize(X, norm='l2', axis=1, copy=True, return_norm=False)


Sklearn 包含了很多种机器学习的方式:
Classification 分类
Regression 回归
Clustering 非监督分类
Dimensionality reduction 数据降维
Model Selection 模型选择
Preprocessing 数据预处理




[4.6] unittest
// unittest.TestCase
py_test\unittest_TestCase.py
python_w py_test\unittest_TestCase.py


// unittest param
py_test\unittest_param.py
python_w py_test\unittest_param.py



[4.7] tqdm-------------进度条库
//tqdm1
py_test\test_tqdm.py
python_w py_test\test_tqdm.py


//tqdm2
py_test\test_tqdm2.py
python_w py_test\test_tqdm2.py

//tqdm3
py_test\test_tqdm3.py
python_w py_test\test_tqdm3.py



[4.8] 




[4.9] 




[4.10] 





[4.11] Jieba
// Jieba--pseg.cut
py_test\jieba_cut.py
python_w py_test\jieba_cut.py


// Jieba--pseg.cut--file
py_test\jieba_cut_a.txt
//我爱北京天安门 
py_test\jieba_cut_b.txt
//我r	爱v  北京ns	天安门ns   x 


py_test\jieba_file_read.py
python_w py_test\jieba_file_read.py






[4.12] 
	


[4.13] 



[5.1] tf.Variable()
v1=tf.Variable(tf.random_normal(shape=[4,3],mean=0,stddev=1),name='v1')
//	[[-1.2115501? ?1.0484737? ?0.55210656]
//	?[-1.5301195? ?0.9060654? -2.6766613 ]
//	?[ 0.27101386 -0.32336152? 0.44544214]
//	?[-0.0120788? -0.3409422? -0.48505628]]
v2=tf.Variable(tf.constant(2),name='v2')
//	2
v3=tf.Variable(tf.ones([4,3]),name='v3')
//	[[1. 1. 1.]
//	?[1. 1. 1.]
//	?[1. 1. 1.]
//	?[1. 1. 1.]]

//生成tensor
tf.zeros(shape, dtype=tf.float32, name=None)
tf.zeros_like(tensor, dtype=None, name=None)
tf.constant(value, dtype=None, shape=None, name='Const')
tf.fill(dims, value, name=None)
tf.ones_like(tensor, dtype=None, name=None)
tf.ones(shape, dtype=tf.float32, name=None)

//生成序列
tf.range(start, limit, delta=1, name='range')
tf.linspace(start, stop, num, name=None)

//生成随机数
tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)
tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)
tf.random_uniform(shape, minval=0.0, maxval=1.0, dtype=tf.float32, seed=None, name=None)
tf.random_shuffle(value, seed=None, name=None)


[5.2] tf.train.Saver.save()
//保存图的变量
save_path = saver.save(sess, "/tmp/model.ckpt")
//加载图的变量
saver.restore(sess, "/tmp/model.ckpt")




[5.3] tf.add()
tf.add()
tf.assign_add(x, 1)
tf.multiply(w, 2)


//	with tf.control_dependencies([x_plus_1]):
//	y = tf.identity(x)
//	y.eval()

py_test\op_identity.py
python_w py_test\op_identity.py



[5.4] tf.group(mul, add)
tf.group(mul, add)
tf.tuple([mul, add])


py_test\op_group.py
python_w py_test\op_group.py



[5.5] tf.gradients 梯度
//
py_test\gradients1.py
python_w py_test\gradients1.py
//	[array([1., 1., 1.], dtype=float32), 
//	array([1., 1., 1.], dtype=float32), 
//	array([2., 2., 2.], dtype=float32), 
//	array([1., 1., 1.], dtype=float32)]


py_test\gradients2.py
python_w py_test\gradients2.py
//	[array([2., 2., 3.], dtype=float32), 
//	array([2., 2., 3.], dtype=float32), 
//	array([5., 4., 7.], dtype=float32), 
//	array([3., 2., 4.], dtype=float32)]


py_test\gradients3.py
python_w py_test\gradients3.py
//	the gradient of y=x[0, 0]+2*x[0, 1]for x is: [array([[1., 2.]], dtype=float32)]


py_test\gradients4.py
python_w py_test\gradients4.py
//	[(3.0, 4.0)]
//	[3.0, 4.0, 12.0]


//----手动验证
py_test\gradients5.py
python_w py_test\gradients5.py
//	[(3.0, 5.0)]
//	[3.0, 5.0, 14.0]



[5.6] tf.data.Dataset
py_test\data_Dataset1.py
python_w py_test\data_Dataset1.py
//	1.0
//	2.0
//	3.0
//	4.0
//	5.0

//----list
py_test\data_Dataset2.py
python_w py_test\data_Dataset2.py
//	[0.50283511 0.3921546 ]
//	[0.53019523 0.78479929]
//	[0.2543726	0.62849479]
//	[0.22100771 0.48973158]
//	[0.71914178 0.67568286]
//	end!

//----disk
py_test\data_Dataset3.py
python_w py_test\data_Dataset3.py
//	{'a': 1.0, 'b': array([0.79249911, 0.15798004])}
//	{'a': 2.0, 'b': array([0.34127329, 0.56827207])}
//	{'a': 3.0, 'b': array([0.8322679 , 0.61611865])}
//	{'a': 4.0, 'b': array([0.65949827, 0.6437763 ])}
//	{'a': 5.0, 'b': array([0.50562221, 0.37971811])}
//	end!

//----tuple
py_test\data_Dataset4.py
python_w py_test\data_Dataset4.py
//	(1.0, array([0.25269596, 0.98681773]))
//	(2.0, array([0.72293645, 0.08887966]))
//	(3.0, array([0.09073945, 0.42811984]))
//	(4.0, array([0.59848085, 0.00249306]))
//	(5.0, array([0.66916095, 0.45611585]))
//	end!

//----map
py_test\data_Dataset5.py
python_w py_test\data_Dataset5.py
//	2.0
//	3.0
//	4.0
//	5.0
//	6.0
//	end!

//----batch--将多个元素组合成batch
py_test\data_Dataset6.py
python_w py_test\data_Dataset6.py
//	{'a': array([1., 2.]), 'b': array([[0.28226126, 0.32874466],
//		   [0.1308661 , 0.07176781]])}
//	{'a': array([3., 4.]), 'b': array([[0.823813  , 0.20713728],
//		   [0.75160344, 0.94561941]])}
//	{'a': array([5.]), 'b': array([[0.21681289, 0.56474561]])}
//	end!

//----shuffle--打乱
py_test\data_Dataset7.py
python_w py_test\data_Dataset7.py
//	{'a': 2.0, 'b': array([0.61422834, 0.68408869])}
//	{'a': 1.0, 'b': array([0.057589  , 0.05745147])}
//	{'a': 3.0, 'b': array([0.59370247, 0.20736014])}
//	{'a': 4.0, 'b': array([0.05181975, 0.67037327])}
//	{'a': 5.0, 'b': array([0.10704603, 0.72817143])}
//	end!


//----repeat--将整个序列重复多次
py_test\data_Dataset8.py
python_w py_test\data_Dataset8.py
//	{'a': 1.0, 'b': array([0.51900078, 0.10005534])}
//	{'a': 2.0, 'b': array([0.8865739 , 0.38145213])}
//	{'a': 3.0, 'b': array([0.68661129, 0.53582187])}
//	{'a': 4.0, 'b': array([0.61606895, 0.04549935])}
//	{'a': 5.0, 'b': array([0.96872654, 0.04734563])}
//	{'a': 1.0, 'b': array([0.51900078, 0.10005534])}
//	{'a': 2.0, 'b': array([0.8865739 , 0.38145213])}
//	{'a': 3.0, 'b': array([0.68661129, 0.53582187])}
//	{'a': 4.0, 'b': array([0.61606895, 0.04549935])}
//	{'a': 5.0, 'b': array([0.96872654, 0.04734563])}
//	end!




[5.7] tf.layers

py_test\layers_dense.py
python_w py_test\layers_dense.py




[5.8] tf.nn.softmax------归一化
//归一化指数函数
//tf.nn.log_softmax

py_test\log_softmax.py
python_w py_test\log_softmax.py


//信息熵(真实*真实)
//	代表的是随机变量或整个系统的不确定性，熵越大，随机变量或系统的不确定性就越大
//	sum(p*log2(1/p)) = 1/2*log2(2)+...= 1/2 * 1 + 1/4 * 2 + 1/8 * 3 + 1/8 * 3 = 1.75
//
//	sum(10个,不平均) = 0.9 * 0.152 + 0.0111 * 6.49 * 9 = 0.785
//	sum(10个,平均)	   = 0.1 * 3.32 * 10				 = 3.32


//交叉熵(真实*非真实)
//	真实分布为基础，非真实分布策略树求和;
//	sum(p*log2(1/q)) = 1/2*log2(4)+... = 2
//
//	sum(10个,不平均) = 0.9 * 3.32 + 0.0111 * 3.32 * 9 = 3.32
//	sum(10个,平均)	   = 0.1 * 3.32 * 10				= 3.32

//相对熵(交叉熵 - 信息熵)
//	KL(p || q) = H(p，q) - H(p) = 2 - 1.75 = 0.25
//	KL(10个,不平均) = 3.32 - 0.785			   = 2.53



[5.9] tf.one_hot

py_test\tf_one_hot.py
python_w py_test\tf_one_hot.py




[5.10] tf.logging

tf.logging.info(">>>instance--%s : %s" %( str(inst_index), str(instance)))

print(one_hot_1.eval(session=sess))

sess.run(tf.Print(train_logits,[train_logits],summarize=134))





[5.11] Estimator------评估器

//Estimator
py_test\tf_Estimator.py
//python_w py_test\tf_Estimator.py


[5.12] tf.Experiment-----实验类
//Experiment（实验）类是定义如何训练模型，并将其与 Estimator 进行集成的方式。




[5.13] tf.Dataset--------数据集

py_test\tf_Dataset.py
//python_w py_test\tf_Dataset.py



[5.14] layer_norm

layer_norm		   
在张量的最后一个维度上运行图层规范化




[5.15] tf.metrics.accuracy 准确度
//accuracy
py_test\tf_accuracy.py
python_w py_test\tf_accuracy.py

//f1score
py_test\tf_metrics_f1score.py
python_w py_test\tf_metrics_f1score.py


//sklearn
py_test\sklearn_metrics1.py
python_w py_test\sklearn_metrics1.py



[5.16] tf.reshape
py_test\test_reshape.py
python_w py_test\test_reshape.py



[5.17] tf.gather---------索引提取
//tf.gather：用一个一维的索引数组，将张量中对应索引的向量提取出来
py_test\test_gather.py
python_w py_test\test_gather.py



[5.18] Hook



[5.19] tf.enable_eager_execution()
//tf.enable_eager_execution
py_test\tf_enable_eager_execution.py
python_w py_test\tf_enable_eager_execution.py



[5.20] tf.summary

//tf.summary
py_test\tf_summary.py
python_w py_test\tf_summary.py
//	AttributeError: module 'tensorflow' has no attribute 'assign_add'


[5.21] tf.map_fn
//
mat_ratio = list(map(lambda x: 1.0/x if not x == 0.0 else float(64.0), mat_ratio))
//
mat_ratio = tf.map_fn(lambda x: tf.cond(x > 0, lambda: 1/x, lambda: float(64.0)), mat_ratio)
//if ... else 是不被识别
//通过tf.cond()进行代替
//tf.cond(x < y, lambda: tf.add(x, z), lambda: tf.square(y))



[5.22] tf.cond
//tf.cond(,,)
py_test\tf_cond.py
python_w py_test\tf_cond.py


//tf.cond 多cond混合
py_test\tf_cond2.py
python_w py_test\tf_cond2.py


//tf.cond -->shape
py_test\tf_cond_shape.py
python_w py_test\tf_cond_shape.py


//tf.cond -->分块
py_test\tf_cond_block.py
python_w py_test\tf_cond_block.py




[5.23] tf.while_loop
//tf.where(,,)
py_test\tf_while.py
python_w py_test\tf_while.py


//tf.where_else
py_test\tf_where_else.py
python_w py_test\tf_where_else.py


//tf.while_loop
py_test\tf_while_loop.py
python_w py_test\tf_while_loop.py


//tf.while_loop--最少2个参数, 不报错
py_test\tf_while_list.py
python_w py_test\tf_while_list.py


//tf.TensorArray--数组stack write read
py_test\tf_TensorArray.py
python_w py_test\tf_TensorArray.py





[5.24] tf.concat
t1 = [[1, 2, 3], [4, 5, 6]]
t2 = [[7, 8, 9], [10, 11, 12]]
tf.concat([t1, t2], 0)	# [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]
tf.concat([t1, t2], 1)	# [[1, 2, 3, 7, 8, 9], [4, 5, 6, 10, 11, 12]]

# tensor t3 with shape [2, 3]
# tensor t4 with shape [2, 3]
tf.shape(tf.concat([t3, t4], 0))  # [4, 3]
tf.shape(tf.concat([t3, t4], 1))  # [2, 6]



[5.25] tf.expand_dims
tf.expand_dims(s, -1)



[5.26] tf.logical_and
//逻辑op:
tf.logical_and
tf.logical_not
tf.logical_or
tf.logical_xor




[5.27] tf.equal
// 比较
py_test\tf_equal.py
python_w py_test\tf_equal.py


//	tf.equal(a,True)
//	tf.not_equal
//	tf.less(x, y)
//	tf.less_equal(x, y)
//	tf.greater
//	tf.greater_equal




[5.28] tf.argmin
//序列比较和索引提取op
tf.argmin
tf.argmax
tf.where
tf.unique




[5.29] transpose
X=tf.transpose(A,[0,2,1])


[5.30] 




[5.31] 




[5.32] 




[5.33] 




[6.1] tf.data.Dataset----tf2.0
py_test\tf2_data_Dataset1.py
python_w py_test\tf2_data_Dataset1.py


[6.2] tf2_model----------Masking
// layers_Masking
py_test\tf2_layers_Masking.py
python_w py_test\tf2_layers_Masking.py


	
[6.3] tf2_K_maximum
// 最大值3 f1 = tf.maximum(a, 3)
// 最小值3 f2 = tf.minimum(a, 3)
py_test\tf2_K_maximum.py
python_w py_test\tf2_K_maximum.py
	
	
[6.4] tf.py_function
def augment_data(image_batch):
	image = tf.py_function(append, inp=[image_batch, tf.image.flip_left_right(image_batch)], Tout=[tf.float32])
	return image

	
[6.5] tf2_loss
py_test\tf2_loss.py
python_w py_test\tf2_loss.py
	
	

[6.6] tf2_keras_clip-----边界值
//逐元素clip（将超出指定范围的数强制变为边界值）
py_test\tf2_keras_clip.py
python_w py_test\tf2_keras_clip.py




[6.7] tf.nn.relu---------激活op
//激活op
tf.nn.relu
tf.nn.relu6
tf.nn.crelu
tf.nn.elu
tf.nn.softplus
tf.nn.softsign
tf.nn.dropout
tf.nn.bias_add
tf.sigmoid
tf.tanh





[6.8] tf.nn.conv2d-------卷积op
//卷积op
tf.nn.convolution
tf.nn.conv2d
tf.nn.depthwise_conv2d
tf.nn.depthwise_conv2d_native
tf.nn.separable_conv2d
tf.nn.atrous_conv2d
tf.nn.atrous_conv2d_transpose
tf.nn.conv2d_transpose
tf.nn.conv1d
tf.nn.conv3d
tf.nn.conv3d_transpose
tf.nn.conv2d_backprop_filter
tf.nn.conv2d_backprop_input
tf.nn.conv3d_backprop_filter_v2
tf.nn.depthwise_conv2d_native_backprop_filter
tf.nn.depthwise_conv2d_native_backprop_input




[6.9] tf.nn.avg_pool-----池化op
//池化op
tf.nn.max_pool
tf.nn.max_pool_with_argmax
tf.nn.avg_pool3d
tf.nn.max_pool3d
tf.nn.fractional_avg_pool
tf.nn.fractional_max_pool
tf.nn.pool

//全局平均池化
GlobalAveragePooling1D




[6.10] tf.nn.l2_normalize归一化op
tf.nn.l2_normalize
tf.nn.local_response_normalization
tf.nn.sufficient_statistics
tf.nn.normalize_moments
tf.nn.moments
tf.nn.weighted_moments
tf.nn.fused_batch_norm
tf.nn.batch_normalization
tf.nn.batch_norm_with_global_normalization





[6.11] tf.nn.l2_loss
//误差损失op
tf.nn.l2_loss
tf.nn.log_poisson_loss
//分类op
tf.nn.sigmoid_cross_entropy_with_logits
tf.nn.softmax
tf.nn.log_softmax
tf.nn.softmax_cross_entropy_with_logits
tf.nn.sparse_softmax_cross_entropy_with_logits
tf.nn.weighted_cross_entropy_with_logits
//查找嵌入tensor的value
tf.nn.embedding_lookup
tf.nn.embedding_lookup_sparse
//候选抽样op
tf.nn.sampled_softmax_loss




[6.12] 




[6.13] 




[6.14] tf2_classify_bys

// tf2_classify_bys
classify:tf2_classify_bys.py
python_w classify:tf2_classify_bys.py


// tf2_classify_sg
//   身高+体重->肥瘦
classify:tf2_classify_sg.h
classify:tf2_classify_sg.py
python_w classify:tf2_classify_sg.py


// tf2_classify_sg
//   次用到的源数据是datasets.load_iris()，iris数据集是一个字典，可以看成150行5列的二维表。
//	 150个样本，每个样本包含了花萼长度、花萼宽度、花瓣长度、花瓣宽度四个特征（前4列）
//	 iris的每个样本都包含了品种信息，即目标属性（第5列，也叫target或label），
//	 其中有5个key键，data记录每个样本四个特征数值，target记录品种数(用0,1,2表示),
//	 target_names是具体品种名称，feature_names是具体的特征名称。
classify:tf2_classify_iris.py
python_w classify:tf2_classify_iris.py


// tf2_classify_num
//   1维数组--决策树
classify:tf2_classify_num.h
classify:tf2_classify_num.py
python_w classify:tf2_classify_num.py


// Keras
//	KerasClassifier  分类器----err
//	KerasRegressor  回归器
//	np_utils.to_categorical
classify:tf2_classify_ks.csv
classify:tf2_classify_ks.py
python_w classify:tf2_classify_ks.py


[6.15] tf2_Dense----------二分类
// tf2_Dense
classify:tf2_classify_num.h
//classify:tf2_classify_Dense.py
//python_w classify:tf2_classify_Dense.py



[6.16] LogisticRegression
// 逻辑回归----err
classify:tf2_Logistic_Regression.py
python_w classify:tf2_Logistic_Regression.py




[6.17] 




[6.18] 




[6.19] 




[6.20] 




[6.21] 




[6.22] 






[7.1] variable constant epsilon
keras.backend.variable(value, dtype=None, name=None, constraint=None)
keras.backend.constant(value, dtype=None, shape=None, name=None)
keras.backend.random_normal_variable(shape, mean, scale, dtype=None, name=None, seed=None)
keras.backend.set_value(x, value)
keras.backend.batch_set_value(tuples)
K.epsilon()
K.eval(kvar)





[7.2] shape int_shape reshape
keras.backend.shape(x)
keras.backend.int_shape(x)
keras.backend.reshape(x, shape)
keras.backend.squeeze(x, axis) #移除 1 个尺寸的维度




[7.3] softmax sigmoid
keras.backend.softmax(x)
keras.backend.softplus(x)
keras.backend.softsign(x)
keras.backend.sigmoid(x)
keras.backend.hard_sigmoid(x)




[7.4] max min sum prod
keras.backend.max(x, axis=None, keepdims=False)
keras.backend.min(x, axis=None, keepdims=False)
keras.backend.sum(x, axis=None, keepdims=False)
keras.backend.prod(x, axis=None, keepdims=False)
keras.backend.cumsum(x, axis=0)
keras.backend.cumprod(x, axis=0)
keras.backend.var(x, axis=None, keepdims=False)  #方差
keras.backend.std(x, axis=None, keepdims=False)  #标准差
keras.backend.mean(x, axis=None, keepdims=False) #均值
keras.backend.maximum(x, y)
keras.backend.minimum(x, y)




[7.5] any all
keras.backend.any(x, axis=None, keepdims=False)
keras.backend.all(x, axis=None, keepdims=False)
keras.backend.argmax(x, axis=-1)
keras.backend.argmin(x, axis=-1)




[7.6] square round
keras.backend.square(x)
keras.backend.abs(x)
keras.backend.round(x)
keras.backend.pow(x, a)




[7.7] clip
keras.backend.clip(x, min_value, max_value) #裁剪




[7.8] repeat
keras.backend.repeat(x, n)
//重复一个 2D 张量。
//如果 x 的尺寸为 (samples, dim) 并且 n 为 2， 则输出的尺寸为 (samples, 2, dim)。



[7.9] arange
keras.backend.arange(start, stop=None, step=1, dtype='int32')
keras.backend.dropout(x, level, noise_shape=None, seed=None)




[7.10] flatten
keras.backend.flatten(x)
keras.backend.batch_flatten(x)
keras.backend.print_tensor(x, message='')


[7.11] 









